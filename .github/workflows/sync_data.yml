name: Sync BJJ App Data (Dev → Prod)

on:
  workflow_dispatch:
    inputs:
      mode:
        description: "Choose mode: dry-run or full-sync"
        required: true
        default: "dry-run"
        type: choice
        options:
          - dry-run
          - full-sync

jobs:
  sync-data:
    runs-on: ubuntu-latest

    env:
      AWS_REGION: ${{ vars.AWS_REGION }}
      AWS_BUCKET_DEV_DUMP: ${{ vars.AWS_BUCKET_DEV_DUMP }}
      AWS_BUCKET_BACKUP: ${{ vars.AWS_BUCKET_BACKUP }}
      PROD_HOST: bjj-prod  # Use SSH alias from ~/.ssh/config

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.x"

      - name: Install dependencies
        run: |
          sudo apt-get update && sudo apt-get install -y jq
          python3 -m pip install --upgrade pip
          pip install "boto3==1.38.37" "botocore>=1.38.37,<1.39.0" "s3transfer>=0.13.0,<0.14.0"
          pip install -r requirements.txt
          pip install awscli

      - name: Configure AWS CLI
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Add SSH host to known_hosts
        run: |
          mkdir -p ~/.ssh
          ssh-keyscan -H $PROD_HOST >> ~/.ssh/known_hosts

      - name: Ensure local Dev DB exists
        run: |
          if [ ! -f db.sqlite3 ]; then
            echo "Creating temporary SQLite DB for GitHub Actions..."
            python3 manage.py migrate --noinput --settings=jiujitsuteria.settings.dev
          fi

      - name: Check if Dev dump JSON exists in S3
        run: |
          if ! aws s3 ls "s3://${AWS_BUCKET_DEV_DUMP}/bjj_data.json" > /dev/null 2>&1; then
            echo "❌ Dev app data JSON not found in S3. Please upload it first."
            exit 1
          fi
          echo "✅ Dev app data JSON exists in S3."

      - name: Download Dev dump JSON (for local validation)
        run: aws s3 cp "s3://${AWS_BUCKET_DEV_DUMP}/bjj_data.json" ./bjj_data.json

      - name: Quick sanity check on JSON (optional)
        run: |
          echo "🔍 Checking JSON structure..."
          jq '.[0].model' bjj_data.json >/dev/null && echo "✅ JSON structure OK."

      - name: Run sync_data.sh
        run: |
          chmod +x scripts/sync_data.sh
          # Pass PROD_HOST as env variable so the script uses SSH alias
          export PROD_HOST=${{ env.PROD_HOST }}
          if [ "${{ github.event.inputs.mode }}" = "dry-run" ]; then
            echo "🔍 Running dry-run..."
            ./scripts/sync_data.sh --dry-run
          else
            echo "🚀 Running full data sync..."
            ./scripts/sync_data.sh
          fi

      - name: Sync Complete
        if: always()
        run: |
          echo "✅ Sync data job finished successfully (mode: ${{ github.event.inputs.mode }})"

